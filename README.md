# Aprimoramento de Modelos de Super-ResoluÃ§Ã£o para Imagens de Tomografia Computadorizada utilizando Fine-Tuning  

<p align="center">
  <a href="README_EN.md">
    <img src="https://img.shields.io/badge/README-English-ğŸ‡¬ğŸ‡§" alt="English">
  </a>
  <a href="https://ele.ufes.br/pt-br/projetos-de-graduacao-202401-e-202402">
    <img src="https://img.shields.io/badge/-Projeto%20de%20GraduaÃ§Ã£o-lightyellow" alt="Projeto de GraduaÃ§Ã£o">
  </a>
</p>


## Ãndice
1. [IntroduÃ§Ã£o](#introduÃ§Ã£o)  
2. [Conjunto de Dados](#conjunto-de-dados)  
3. [Etapas do Processo](#etapas-do-processo)  
4. [Escolhas MetodolÃ³gicas](#escolhas-metodolÃ³gicas)  
5. [MÃ©tricas de AvaliaÃ§Ã£o](#mÃ©tricas-de-avaliaÃ§Ã£o)
6. [Resultados Quantitativos](#resultados-quantitativos)
7. [Estrutura do Projeto](#estrutura-do-projeto)  
8. [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#instalaÃ§Ã£o-e-execuÃ§Ã£o)  


---

## IntroduÃ§Ã£o

Este repositÃ³rio contÃ©m o cÃ³digo desenvolvido no Ã¢mbito de um trabalho acadÃªmico cujo foco Ã© o aprimoramento de imagens de tomografia computadorizada (TC) de baixa dosagem por meio de tÃ©cnicas de super-resoluÃ§Ã£o baseadas em aprendizado profundo. A motivaÃ§Ã£o central estÃ¡ associada Ã  possibilidade de melhorar a qualidade visual e estrutural das imagens mÃ©dicas sem aumentar a exposiÃ§Ã£o do paciente Ã  radiaÃ§Ã£o ionizante, utilizando exclusivamente pÃ³s-processamento computacional.

O projeto baseia-se na adaptaÃ§Ã£o de modelos de super-resoluÃ§Ã£o prÃ©-treinados em imagens naturais para o domÃ­nio especÃ­fico da tomografia computadorizada, utilizando a tÃ©cnica de fine-tuning. O objetivo principal Ã© avaliar o impacto desse ajuste fino no desempenho dos modelos, comparando a inferÃªncia direta com a inferÃªncia apÃ³s o fine-tuning, e analisar se a especializaÃ§Ã£o ao domÃ­nio mÃ©dico contribui para ganho de qualidade perceptual e maior fidelidade estrutural nas imagens reconstruÃ­das. Toda a implementaÃ§Ã£o foi realizada com ferramentas gratuitas e de cÃ³digo aberto, visando reprodutibilidade e acessibilidade.

---

## Conjunto de Dados

O conjunto de dados utilizado neste projeto Ã© o LoDoPaB-CT (Low-Dose Parallel Beam â€“ Computed Tomography), comumente empregado para estudos de reconstruÃ§Ã£o e aprimoramento de imagens de tomografia computadorizada de baixa dosagem. Esse dataset Ã© composto por imagens simuladas de TC do tÃ³rax humano, permitindo a formaÃ§Ã£o de pares correspondentes de baixa resoluÃ§Ã£o e alta resoluÃ§Ã£o.

No contexto deste projeto, o dataset Ã© organizado em subconjuntos de treino, validaÃ§Ã£o e teste, possibilitando tanto o processo de fine-tuning supervisionado quanto a avaliaÃ§Ã£o quantitativa dos resultados. As imagens originais sÃ£o fornecidas em formato HDF5 e passam por uma etapa de processamento, na qual sÃ£o convertidas para o formato BMP, tornando-se compatÃ­veis com os modelos de super-resoluÃ§Ã£o empregados.

---

## Etapas do Processo

O fluxo geral do projeto estÃ¡ organizado nas seguintes etapas:

1. **PreparaÃ§Ã£o dos dados**  
   - OrganizaÃ§Ã£o dos conjuntos de treino, validaÃ§Ã£o e teste  
   - ConversÃ£o das imagens do formato HDF5 para BMP  

2. **InferÃªncia direta**  
   - AplicaÃ§Ã£o dos modelos prÃ©-treinados sem ajuste adicional  
   - GeraÃ§Ã£o das imagens super-resolvidas de referÃªncia (baseline)  

3. **Fine-tuning dos modelos**  
   - Ajuste supervisionado dos pesos finais das redes  
   - EspecializaÃ§Ã£o dos modelos ao domÃ­nio de TC de baixa dosagem  

4. **InferÃªncia pÃ³s fine-tuning**  
   - GeraÃ§Ã£o das imagens reconstruÃ­das com os modelos ajustados  

5. **AvaliaÃ§Ã£o quantitativa**  
   - CÃ¡lculo das mÃ©tricas de qualidade  
   - ComparaÃ§Ã£o entre inferÃªncia direta e pÃ³s fine-tuning  

---

## Escolhas MetodolÃ³gicas

As principais decisÃµes adotadas no desenvolvimento do projeto foram:

- Uso de modelos prÃ©-treinados, reduzindo custo computacional e tempo de treinamento  
- AplicaÃ§Ã£o de fine-tuning raso, com ajuste apenas das camadas finais das redes  
- UtilizaÃ§Ã£o do dataset LoDoPaB-CT
- SeparaÃ§Ã£o explÃ­cita entre treino, validaÃ§Ã£o e teste para garantir avaliaÃ§Ã£o consistente  

Essas escolhas buscam equilibrar desempenho, reprodutibilidade e viabilidade computacional.

---

## MÃ©tricas de AvaliaÃ§Ã£o

A avaliaÃ§Ã£o do desempenho dos modelos de super-resoluÃ§Ã£o Ã© realizada por meio das seguintes mÃ©tricas:

**PSNR (Peak Signal-to-Noise Ratio)**
- Avalia a relaÃ§Ã£o sinal-ruÃ­do entre a imagem reconstruÃ­da e a imagem de referÃªncia. Valores mais altos indicam melhor qualidade de reconstruÃ§Ã£o.

**SSIM (Structural Similarity Index Measure)**
- Mede a similaridade estrutural entre a imagem super-resolvida e a imagem de referÃªncia, considerando luminÃ¢ncia, contraste e estrutura.

**PI (Perceptual Index)**
- MÃ©trica perceptual que combina informaÃ§Ãµes de qualidade visual para avaliar a naturalidade das imagens reconstruÃ­das. Valores menores indicam melhor qualidade perceptual.

Essas mÃ©tricas permitem analisar de forma complementar a fidelidade estrutural e a qualidade visual das imagens reconstruÃ­das.

---

## Resultados Quantitativos

Os resultados quantitativos evidenciam que o processo de fine-tuning promove melhorias consistentes em relaÃ§Ã£o Ã  inferÃªncia direta, tanto no domÃ­nio de resoluÃ§Ã£o original quanto no domÃ­nio de resoluÃ§Ã£o reduzida. Observa-se aumento significativo nos valores mÃ©dios de PSNR e SSIM, acompanhado por reduÃ§Ã£o do Ãndice de PercepÃ§Ã£o (PI), indicando simultaneamente maior fidelidade estrutural e melhor qualidade perceptual das imagens reconstruÃ­das. Os boxplots associados reforÃ§am essa tendÃªncia, ao evidenciar menor dispersÃ£o dos resultados e deslocamento das distribuiÃ§Ãµes em favor dos modelos ajustados, quando comparados aos mÃ©todos sem fine-tuning e ao mÃ©todo de referÃªncia FBP.

Os resultados a seguir apresentam a mÃ©dia e o desvio padrÃ£o das mÃ©tricas PSNR, SSIM e PI para os diferentes mÃ©todos avaliados, considerando os domÃ­nios de resoluÃ§Ã£o original e reduzida. Observa-se que os modelos submetidos ao processo de fine-tuning apresentam melhorias consistentes em relaÃ§Ã£o Ã  inferÃªncia direta e ao mÃ©todo de referÃªncia FBP.

##### Tabela 1 â€“ Resultados no domÃ­nio de resoluÃ§Ã£o original (362Ã—362 pixels)

| MÃ©todo               | ResoluÃ§Ã£o de Treinamento | PSNR (â†‘)           | SSIM (â†‘)           | PI (â†“)            |
|----------------------|--------------------------|--------------------|--------------------|-------------------|
| FBP                  | â€“                        | 18,81 Â± 1,83       | 0,34 Â± 0,09        | 4,11 Â± 1,11       |
| Real-ESRGAN (pre)    | â€“                        | 19,24 Â± 2,07       | 0,41 Â± 0,09        | 4,68 Â± 1,01       |
| HAT (pre)            | â€“                        | 17,12 Â± 2,33       | 0,31 Â± 0,09        | 3,73 Â± 1,05       |
| Real-ESRGAN (FT)     | 362Ã—362                  | 28,75 Â± 3,33       | 0,76 Â± 0,14        | 4,08 Â± 0,58       |
| Real-ESRGAN (FT)     | 240Ã—240                  | 28,43 Â± 3,46       | 0,71 Â± 0,14        | 2,53 Â± 0,41       |
| HAT (FT)             | 240Ã—240                  | 26,98 Â± 3,04       | 0,68 Â± 0,13        | 3,59 Â± 0,62       |

##### Tabela 2 â€“ Resultados no domÃ­nio de resoluÃ§Ã£o reduzida (240Ã—240 pixels)

| MÃ©todo               | ResoluÃ§Ã£o de Treinamento | PSNR (â†‘)           | SSIM (â†‘)           | PI (â†“)            |
|----------------------|--------------------------|--------------------|--------------------|-------------------|
| FBP                  | â€“                        | 19,40 Â± 1,89       | 0,47 Â± 0,09        | 5,60 Â± 1,72       |
| Real-ESRGAN (pre)    | â€“                        | 19,62 Â± 2,13       | 0,57 Â± 0,08        | 5,12 Â± 1,46       |
| HAT (pre)            | â€“                        | 17,29 Â± 2,30       | 0,41 Â± 0,09        | 5,62 Â± 2,00       |
| Real-ESRGAN (FT)     | 362Ã—362                  | 28,99 Â± 3,02       | 0,80 Â± 0,11        | 4,88 Â± 0,82       |
| Real-ESRGAN (FT)     | 240Ã—240                  | 29,63 Â± 3,44       | 0,81 Â± 0,11        | 3,46 Â± 0,72       |
| HAT (FT)             | 240Ã—240                  | 27,67 Â± 3,01       | 0,77 Â± 0,10        | 4,86 Â± 0,78       |


Os diagramas de caixa (boxplots) a seguir ilustram a distribuiÃ§Ã£o das mÃ©tricas PSNR, SSIM e PI para os diferentes mÃ©todos avaliados, evidenciando o ganho obtido com o *fine-tuning* e a reduÃ§Ã£o da dispersÃ£o dos resultados em relaÃ§Ã£o Ã  inferÃªncia direta.

##### ResoluÃ§Ã£o Original (362Ã—362 pixels)
![Boxplots - ResoluÃ§Ã£o Original](/Others/Metrics/Results/boxplot_res_original.png)

##### ResoluÃ§Ã£o Reduzida (240Ã—240 pixels)
![Boxplots - ResoluÃ§Ã£o Reduzida](/Others/Metrics/Results/boxplot_res_reduzida.png)

Os arquivos de resultados completos estÃ£o disponÃ­veis na pasta [`Results`](/Others/Metrics/Results/), a qual contÃ©m tanto as figuras dos boxplots quanto o arquivo com as mÃ©tricas individuais calculadas para todas as imagens reconstruÃ­das neste experimento.

---

## Estrutura do Projeto

A organizaÃ§Ã£o dos arquivos e diretÃ³rios do repositÃ³rio segue a estrutura abaixo.  
**Algumas pastas do projeto contÃªm um arquivo denominado `instruction.md`**, o qual descreve o propÃ³sito daquela pasta, os arquivos que ela armazena e o que acontece com seu conteÃºdo ao longo da execuÃ§Ã£o do pipeline.

```text
Fine-Tuning-for-Computed-Tomography/
â”œâ”€ Datasets/
â”‚  â”œâ”€ test/         - Dataset com as imagens de teste
â”‚  â”œâ”€ train/        - Dataset com as imagens de treino
â”‚  â”œâ”€ validation/   - Dataset com as imagens de validaÃ§Ã£o
â”œâ”€ Models/
â”‚  â”œâ”€ checkpoints/  - Modelos gerados pelo treinamento
â”œâ”€ Others/
â”‚  â”œâ”€ Logs/         - Registro de log da execuÃ§Ã£o
â”‚  â””â”€ Metrics/      - Resultados das mÃ©tricas calculadas
â”œâ”€ src/
â”‚  â”œâ”€ util/
â”‚  â”‚  â”œâ”€ hat_arch.py            - DependÃªncias para execuÃ§Ã£o do HAT
â”‚  â”‚  â”œâ”€ util_basicsr.py        - Ajustes na biblioteca BasicSR
â”‚  â”‚  â””â”€ utils.py               - FunÃ§Ãµes auxiliares
â”‚  â”œâ”€ fine_tune.py              - Treinamento (fine-tuning) dos modelos
â”‚  â”œâ”€ inference.py              - InferÃªncia dos modelos
â”‚  â”œâ”€ main.py                   - Script principal de orquestraÃ§Ã£o
â”‚  â”œâ”€ metrics.py                - CÃ¡lculo das mÃ©tricas
â”‚  â”œâ”€ namelist.py               - ConfiguraÃ§Ãµes da execuÃ§Ã£o
â”‚  â””â”€ pre_processing.py         - ConversÃ£o HDF5 para BMP
â”œâ”€ environment.yml              - Ambiente Conda com dependÃªncias
â””â”€ README.md
```

---
## InstalaÃ§Ã£o e ExecuÃ§Ã£o

As instruÃ§Ãµes de instalaÃ§Ã£o e execuÃ§Ã£o seguem o fluxo abaixo:

### 1. Instale o Anaconda
- https://www.anaconda.com/download/

### 2. Crie o ambiente virtual
```python
conda create -y -n .venv_FT python=3.10
```

### 3. Ative o ambiente virtual
```python
conda activate .venv_FT
```

### 4. Instale as bibliotecas partir do environment.yml
```python
conda env update -n .venv_FT -f environment.yml
```
### 5. Adicione o Dataset na pasta Datasets
- Siga as instruÃ§Ãµes descritas nos arquivos `instruction.md` dentro da pasta Datasets.

### 6. Edite o arquivo `namelist.py`
- Presente na pasta `src`, informe a informaÃ§Ãµes solicitadas

### 7. Execute o cÃ³digo
```python
python src/main.py
```

### 8. Acompanhe o andamento atravÃ©s dos registros de log
- DisponÃ­vel na pasta: `Others/logs`

---

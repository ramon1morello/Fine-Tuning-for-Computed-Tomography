# Aprimoramento de Modelos de Super-ResoluÃ§Ã£o para Imagens de Tomografia Computadorizada utilizando Fine-Tuning  

<p align="center">
  <a href="README_EN.md">
    <img src="https://img.shields.io/badge/README-English-ğŸ‡¬ğŸ‡§" alt="English">
  </a>
  <a href="https://ele.ufes.br/pt-br/projetos-de-graduacao-202401-e-202402">
    <img src="https://img.shields.io/badge/-Projeto%20de%20GraduaÃ§Ã£o-lightyellow" alt="Projeto de GraduaÃ§Ã£o">
  </a>
</p>


## Ãndice
1. [IntroduÃ§Ã£o](#introduÃ§Ã£o)  
2. [Conjunto de Dados](#conjunto-de-dados)  
3. [Etapas do Processo](#etapas-do-processo)  
4. [Escolhas MetodolÃ³gicas](#escolhas-metodolÃ³gicas)  
5. [MÃ©tricas de AvaliaÃ§Ã£o](#mÃ©tricas-de-avaliaÃ§Ã£o)  
6. [Estrutura do Projeto](#estrutura-do-projeto)  
7. [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#instalaÃ§Ã£o-e-execuÃ§Ã£o)  


---

## IntroduÃ§Ã£o

Este repositÃ³rio contÃ©m o cÃ³digo desenvolvido no Ã¢mbito de um trabalho acadÃªmico cujo foco Ã© o aprimoramento de imagens de tomografia computadorizada (TC) de baixa dosagem por meio de tÃ©cnicas de super-resoluÃ§Ã£o baseadas em aprendizado profundo. A motivaÃ§Ã£o central estÃ¡ associada Ã  possibilidade de melhorar a qualidade visual e estrutural das imagens mÃ©dicas sem aumentar a exposiÃ§Ã£o do paciente Ã  radiaÃ§Ã£o ionizante, utilizando exclusivamente pÃ³s-processamento computacional.

O projeto baseia-se na adaptaÃ§Ã£o de modelos de super-resoluÃ§Ã£o prÃ©-treinados em imagens naturais para o domÃ­nio especÃ­fico da tomografia computadorizada, utilizando a tÃ©cnica de fine-tuning. O objetivo principal Ã© avaliar o impacto desse ajuste fino no desempenho dos modelos, comparando a inferÃªncia direta com a inferÃªncia apÃ³s o fine-tuning, e analisar se a especializaÃ§Ã£o ao domÃ­nio mÃ©dico contribui para ganho de qualidade perceptual e maior fidelidade estrutural nas imagens reconstruÃ­das. Toda a implementaÃ§Ã£o foi realizada com ferramentas gratuitas e de cÃ³digo aberto, visando reprodutibilidade e acessibilidade.

---

## Conjunto de Dados

O conjunto de dados utilizado neste projeto Ã© o LoDoPaB-CT (Low-Dose Parallel Beam â€“ Computed Tomography), comumente empregado para estudos de reconstruÃ§Ã£o e aprimoramento de imagens de tomografia computadorizada de baixa dosagem. Esse dataset Ã© composto por imagens simuladas de TC do tÃ³rax humano, permitindo a formaÃ§Ã£o de pares correspondentes de baixa resoluÃ§Ã£o e alta resoluÃ§Ã£o.

No contexto deste projeto, o dataset Ã© organizado em subconjuntos de treino, validaÃ§Ã£o e teste, possibilitando tanto o processo de fine-tuning supervisionado quanto a avaliaÃ§Ã£o quantitativa dos resultados. As imagens originais sÃ£o fornecidas em formato HDF5 e passam por uma etapa de processamento, na qual sÃ£o convertidas para o formato BMP, tornando-se compatÃ­veis com os modelos de super-resoluÃ§Ã£o empregados.

---

## Etapas do Processo

O fluxo geral do projeto estÃ¡ organizado nas seguintes etapas:

1. **PreparaÃ§Ã£o dos dados**  
   - OrganizaÃ§Ã£o dos conjuntos de treino, validaÃ§Ã£o e teste  
   - ConversÃ£o das imagens do formato HDF5 para BMP  

2. **InferÃªncia direta**  
   - AplicaÃ§Ã£o dos modelos prÃ©-treinados sem ajuste adicional  
   - GeraÃ§Ã£o das imagens super-resolvidas de referÃªncia (baseline)  

3. **Fine-tuning dos modelos**  
   - Ajuste supervisionado dos pesos finais das redes  
   - EspecializaÃ§Ã£o dos modelos ao domÃ­nio de TC de baixa dosagem  

4. **InferÃªncia pÃ³s fine-tuning**  
   - GeraÃ§Ã£o das imagens reconstruÃ­das com os modelos ajustados  

5. **AvaliaÃ§Ã£o quantitativa**  
   - CÃ¡lculo das mÃ©tricas de qualidade  
   - ComparaÃ§Ã£o entre inferÃªncia direta e pÃ³s fine-tuning  

---

## Escolhas MetodolÃ³gicas

As principais decisÃµes adotadas no desenvolvimento do projeto foram:

- Uso de modelos prÃ©-treinados, reduzindo custo computacional e tempo de treinamento  
- AplicaÃ§Ã£o de fine-tuning raso, com ajuste apenas das camadas finais das redes  
- UtilizaÃ§Ã£o do dataset LoDoPaB-CT
- SeparaÃ§Ã£o explÃ­cita entre treino, validaÃ§Ã£o e teste para garantir avaliaÃ§Ã£o consistente  

Essas escolhas buscam equilibrar desempenho, reprodutibilidade e viabilidade computacional.

---

## MÃ©tricas de AvaliaÃ§Ã£o

A avaliaÃ§Ã£o do desempenho dos modelos de super-resoluÃ§Ã£o Ã© realizada por meio das seguintes mÃ©tricas:

**PSNR (Peak Signal-to-Noise Ratio)**
- Avalia a relaÃ§Ã£o sinal-ruÃ­do entre a imagem reconstruÃ­da e a imagem de referÃªncia. Valores mais altos indicam melhor qualidade de reconstruÃ§Ã£o.

**SSIM (Structural Similarity Index Measure)**
- Mede a similaridade estrutural entre a imagem super-resolvida e a imagem de referÃªncia, considerando luminÃ¢ncia, contraste e estrutura.

**PI (Perceptual Index)**
- MÃ©trica perceptual que combina informaÃ§Ãµes de qualidade visual para avaliar a naturalidade das imagens reconstruÃ­das. Valores menores indicam melhor qualidade perceptual.

Essas mÃ©tricas permitem analisar de forma complementar a fidelidade estrutural e a qualidade visual das imagens reconstruÃ­das.

---

## Estrutura do Projeto

A organizaÃ§Ã£o dos arquivos e diretÃ³rios do repositÃ³rio segue a estrutura abaixo.  
**Algumas pastas do projeto contÃªm um arquivo denominado `instruction.md`**, o qual descreve o propÃ³sito daquela pasta, os arquivos que ela armazena e o que acontece com seu conteÃºdo ao longo da execuÃ§Ã£o do pipeline.

```text
Fine-Tuning-for-Computed-Tomography/
â”œâ”€ Datasets/
â”‚  â”œâ”€ test/         - Dataset com as imagens de teste
â”‚  â”œâ”€ train/        - Dataset com as imagens de treino
â”‚  â”œâ”€ validation/   - Dataset com as imagens de validaÃ§Ã£o
â”œâ”€ Models/
â”‚  â”œâ”€ checkpoints/  - Modelos gerados pelo treinamento
â”œâ”€ Others/
â”‚  â”œâ”€ Logs/         - Registro de log da execuÃ§Ã£o
â”‚  â””â”€ Metrics/      - Resultados das mÃ©tricas calculadas
â”œâ”€ src/
â”‚  â”œâ”€ util/
â”‚  â”‚  â”œâ”€ hat_arch.py            - DependÃªncias para execuÃ§Ã£o do HAT
â”‚  â”‚  â”œâ”€ util_basicsr.py        - Ajustes na biblioteca BasicSR
â”‚  â”‚  â””â”€ utils.py               - FunÃ§Ãµes auxiliares
â”‚  â”œâ”€ fine_tune.py              - Treinamento (fine-tuning) dos modelos
â”‚  â”œâ”€ inference.py              - InferÃªncia dos modelos
â”‚  â”œâ”€ main.py                   - Script principal de orquestraÃ§Ã£o
â”‚  â”œâ”€ metrics.py                - CÃ¡lculo das mÃ©tricas
â”‚  â”œâ”€ namelist.py               - ConfiguraÃ§Ãµes da execuÃ§Ã£o
â”‚  â””â”€ pre_processing.py         - ConversÃ£o HDF5 para BMP
â”œâ”€ environment.yml              - Ambiente Conda com dependÃªncias
â””â”€ README.md
```

---
## InstalaÃ§Ã£o e ExecuÃ§Ã£o

As instruÃ§Ãµes de instalaÃ§Ã£o e execuÃ§Ã£o seguem o fluxo abaixo:

### 1. Instale o Anaconda
- https://www.anaconda.com/download/

### 2. Crie o ambiente virtual
```python
conda create -y -n .venv_FT python=3.10
```

### 3. Ative o ambiente virtual
```python
conda activate .venv_FT
```

### 4. Instale as bibliotecas partir do environment.yml
```python
conda env update -n .venv_FT -f environment.yml
```
### 5. Adicione o Dataset na pasta Datasets
- Siga as instruÃ§Ãµes descritas nos arquivos `instruction.md` dentro da pasta Datasets.

### 6. Edite o arquivo `namelist.py`
- Presente na pasta `src`, informe a informaÃ§Ãµes solicitadas

### 7. Execute o cÃ³digo
```python
python src/main.py
```

### 8. Acompanhe o andamento atravÃ©s dos registros de log
- DisponÃ­vel na pasta: `Others/logs`

---
